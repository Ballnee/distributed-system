# distributed-system  
#### 构建分布式系统的三大难点：  

#####   1.可扩展性  

​	假设我做的小网站忽然大火，被一亿人访问，我必然需要更多的服务器去提供服务，一部分人访问服务器1，一部分人访问服务器2，这个时候数据库成为了瓶颈。如果你构建了一个系统，并且只要增加计算机的数量，系统就能相应提高性能或者吞吐量，这将会是一个巨大的成果，因为计算机只需要花钱就可以买到但是成倍增加的服务器，不一定可以成倍的增加我系统的性能，当人们使用一整个机房的计算机来构建大型网站的时候，为了获取对应的性能，必须要时刻考虑可扩展性。你需要仔细设计系统，才能获得与计算机数量匹配的性能。

#####   2.容错性  

​     我们的一台服务器是不容易出错的，但是成千上万的服务器共同构建的系统几乎每天都有服务器宕机，我们必须保证系统正常提供服务，需要保持容错，最好是提供恢复功能，做容错有两点方法：1.存在副本 2.数据持久化。

#####   3.一致性  

   	 系统提供一致性是非常必须的，一致性也存在两种：强一致性和最终一致性。因为网络是不可靠的。 
    强一致带来的昂贵的通信问题，必须所有副本都存储了数据再返回给用户延时将非常高。  
   人们常常会使用弱一致系统，你只需要更新最近的数据副本，并且只需要从最近的副本获取数据  

##### **6.824学习代码**

##### 1.MapReduce：  

  **论文核心：**

  ![](D:\distributed-system\mapreduce流程.webp)

​	启动MapReduce, 将输入文件切分成大小在16-64MB之间的文件，然后在一组多个机器上启动用户程序其中一个副本将成为master, 余下成为worker。

​	Master给worker指定任务（M个map任务，R个reduce任务），Master开始启动在map阶段，Master选择空闲的worker给予map任务，实现的过程实际worker一直请求任务。  

​	Map worker 接收切分后的input输入文件在GFS上的路径，执行Map函数，将结果缓存到内存，缓存后的中间结果会周期性的写到本地磁盘，并切分成R份（reducer数量），R个文件的位置会发送给master,master会暂存这些中间文件的位置信息和大小信息。

​	当所有map任务完成后 Master进入reduce阶段，并且将reduce任务转发给reducer，Reduce worker 收到中间文件的位置信息，通过RPC读取中间文件。  

​    读取完先根据中间<k, v>排序，然后按照key分组、合并Reduce worker在排序后的数据上迭代，将中间<k, v> 交给reduce 函数处理。最终结果写给对应的output文件（分片）。
  **存在问题：**  
​    Google当时面临的问题是，他们需要在TB级别的数据上进行大量的计算。比如说，为所有的网页创建索引，分析整个互联网的链接路径并得出最重要或者最权威的网页。  
​    构建索引基本上等同于对整个数据做排序，而排序比较费时。如果用一台计算机对整个互联网数据进行排序，要花费多长时间呢，需要同时使用上千台计算机的算力。  
  **解决问题：**  
​    MapReduce的思想是，应用程序设计人员和分布式运算的使用者，只需要写简单的Map函数和Reduce函数，而不需要知道任何有关分布式的事情，MapReduce框架会处理剩下的事情。  
​    MapReduce框架的出现解决了这些问题。它可以将一个大规模的数据集分成若干个小的数据块，然后将这些小数据块分配给多个计算节点并行处理。每个计算节点可以独立地对自己分配的数据块进行计算，并将计算结果返回给框架。框架会将所有计算节点返回的结果合并起来，得到最终的处理结果。具体地，MapReduce框架通过以下两个阶段实现数据处理： 
​       Map阶段：在这个阶段，MapReduce框架将输入的大规模数据集划分成若干个小的数据块，并将这些小数据块分配给多个计算节点并行处理。每个计算节点会对自己分配的数据块进行一些简单的计算和转换，并将计算结果输出成键值对的形式。
​       Reduce阶段：在这个阶段，MapReduce框架将Map阶段的输出结果按照键进行分组，并将同一组中的所有值进行合并计算。每个计算节点会处理其中的一组数据，并将最终结果返回给框架代码。
   **优化：**  
​        论文提的的combiner函数和快结束时的辅助worker。
​       1.数据本地化优化：MapReduce 的性能很大程度上依赖于数据的分布和传输。如果数据本地化，即 Map 和 Reduce 任务可以在同一个节点上运行，那么可以大大减少数据传输的开销  
​       2.压缩技术优化：在 MapReduce 运行过程中，会产生大量的中间数据，因此，采用压缩技术可以减少数据传输的带宽消耗，从而提高性能。  
​       3.合并操作优化：在 MapReduce 运行过程中，Reduce 阶段的输入数据可能很大，因此可以采用合并操作来减少输入数据的数量，从而提高 Reduce 的性能。  
​       4.算法优化：MapReduce 在处理大规模数据时，需要考虑算法的效率。因此，可以针对具体的问题，优化算法，减少 Map 和 Reduce 的执行时间，从而提高整体性能。  
​    **824实现MapReduce：** 
​        	输入输出都在本地文件系统：在分布式场景则使用GFS。
   **上锁：**
   	对于使用RPC调用的函数都需要上锁，但是实现master的任务队列可以使用go的chan，线程安全。 其实应该也可以实现lock_free的写法，把master对象绑定进chan，当worker调用请求任务是需要可以拿到chan里面唯一的master，不然则等待。  
  **不使用workerId：**  
​       对于failed的任务等待超时即可。但是性能要损失，相当于对于操作慢的worker依然可以请求任务。master保留中间结果的位置和大小，使用多线程模拟多服务器，周期性向worker发送心跳检测如果worker失联一段时间，master将worker标记成failed worker失效之后，已完成的map task被重新标记为idle，已完成的reduce task不需要改变原因是：map的结果被写在local disk，worker machine 宕机会导致map的结果丢失；reduce结果存储在GFS，不会随着machine down丢失对于in-progress 且超时的任务，启动backup执行 
​      
​       